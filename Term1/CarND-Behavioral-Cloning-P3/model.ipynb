{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def _normalize_grayscale_bak(image_data):\n",
    "    '''\n",
    "    Normalize the data features to the variable X_normalized\n",
    "    '''\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "def _normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "def _cropping_image(image_data):\n",
    "    \"\"\"\n",
    "    50 rows pixels from the top of the image\n",
    "    20 rows pixels from the bottom of the image\n",
    "    0 columns of pixels from the left of the image\n",
    "    0 columns of pixels from the right of the image\n",
    "    (height, width, channels)\n",
    "    \"\"\"\n",
    "    img_roi_x      = 50  \n",
    "    img_roi_y      = 0  \n",
    "    img_roi_height = image_data.shape[0] - 50 - 20\n",
    "    img_roi_width  = image_data.shape[1]                                                                       \n",
    "    return image_data[img_roi_x:(img_roi_x+img_roi_height),img_roi_y:(img_roi_y+img_roi_width)]\n",
    "\n",
    "def image_preprocess(file_path):\n",
    "    '''\n",
    "    '''\n",
    "    # 1. load image\n",
    "    origan_image = cv2.imread(file_path.strip())\n",
    "    # 2. turn image to gray\n",
    "    gray_image = cv2.cvtColor(origan_image, cv2.COLOR_BGR2GRAY)\n",
    "    # 3. cropping image\n",
    "    cropped_image = _cropping_image(gray_image)\n",
    "    # 5. normalize image\n",
    "    normalize_image = _normalize_grayscale(cropped_image)\n",
    "    # 6. reshape\n",
    "    image_size = normalize_image.shape\n",
    "    reshape_image = np.reshape(normalize_image, (image_size[0], image_size[1], 1) )\n",
    "    #print(reshape_image.shape)\n",
    "    return reshape_image\n",
    "    \n",
    "def data_generator(csv_file, batch_size=80, left_camera_compl=0.2, right_camera_compl=-0.2):\n",
    "    \"\"\"\n",
    "    Image generator. Returns batches of images indefinitely\n",
    "    - path : path to csv file\n",
    "    - batch_size : batch size\n",
    "    \"\"\"\n",
    "    csv_data = pds.read_csv(csv_file)\n",
    "    \n",
    "    data_left_camera = csv_data['left']\n",
    "    data_center_camera = csv_data['center']\n",
    "    data_right_camera = csv_data['right']\n",
    "    data_steering = csv_data['steering']\n",
    "    print(csv_data.shape)\n",
    "    \n",
    "    corrent_index = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    while 1 :\n",
    "        \n",
    "        if corrent_index >= len(csv_data) :\n",
    "            corrent_index = 0\n",
    "            \n",
    "        images_left_camera = image_preprocess(data_left_camera[corrent_index])\n",
    "        images_center_camera = image_preprocess(data_center_camera[corrent_index])\n",
    "        images_right_camera = image_preprocess(data_right_camera[corrent_index])\n",
    "        steering_angle = data_steering[corrent_index]\n",
    "        \n",
    "        features.append(images_left_camera)\n",
    "        labels.append(steering_angle+left_camera_compl)\n",
    "        features.append(np.fliplr(images_left_camera))\n",
    "        labels.append(-(steering_angle+left_camera_compl))\n",
    "        features.append(images_center_camera)\n",
    "        labels.append(steering_angle)\n",
    "        features.append(np.fliplr(images_center_camera))\n",
    "        labels.append(-(steering_angle))\n",
    "        features.append(images_right_camera)\n",
    "        labels.append(steering_angle+right_camera_compl)\n",
    "        features.append(np.fliplr(images_right_camera))\n",
    "        labels.append(-(steering_angle+right_camera_compl))\n",
    "        \n",
    "        corrent_index += 1;\n",
    "        \n",
    "        if(len(features) >= batch_size):\n",
    "            #print(np.array(features).shape, np.array(labels).shape)\n",
    "            yield (np.array(features), np.array(labels))\n",
    "            features = []\n",
    "            labels = []\n",
    "            \n",
    "def create_keras_model(feature_shape=(90,320,1)):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    #\n",
    "    #model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=feature_shape)) \n",
    "    #\n",
    "    model.add(Conv2D(24, 5, 5, activation='relu', input_shape=feature_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    #\n",
    "    model.add(Conv2D(36, 5, 5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    #\n",
    "    model.add(Conv2D(48, 5, 5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    #\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    #\n",
    "    #model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    #\n",
    "    model.add(Flatten())\n",
    "    #\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    return model\n",
    "    \n",
    "def train_model(data_generator):\n",
    "    '''\n",
    "    CarND-Behavioral-Cloning-P3\n",
    "    '''\n",
    "    bhvcln_model = create_keras_model()\n",
    "    print(bhvcln_model.summary)\n",
    "    \n",
    "    bhvcln_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    # train model\n",
    "    bhvcln_model.fit_generator(data_generator, samples_per_epoch=24000, nb_epoch=20)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    data_gene = data_generator('driving_log.csv')\n",
    "    train_model(data_gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
